{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "saving-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from layers import Dense, Embedding, Conv1d\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "burning-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(sentences, src_vocab, tgt_vocab):\n",
    "    input_batch = [[src_vocab[n] for n in sentences[0].split()]]\n",
    "    output_batch = [[tgt_vocab[n] for n in sentences[1].split()]]\n",
    "    target_batch = [[tgt_vocab[n] for n in sentences[2].split()]]\n",
    "    return Tensor(input_batch, mindspore.int32), Tensor(output_batch, mindspore.int32), Tensor(target_batch, mindspore.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resistant-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoid_encoding_table(n_position, d_model):\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "    return Tensor(sinusoid_table, mindspore.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confirmed-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "    \n",
    "    pad_attn_mask = seq_k.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.broadcast_to((batch_size, len_q, len_k))  # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parallel-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequent_mask(seq):\n",
    "    attn_shape = [seq.shape[0], seq.shape[1], seq.shape[1]]\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
    "    subsequent_mask = Tensor.from_numpy(subsequent_mask).to(mindspore.uint8)\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "capable-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Cell):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(axis=-1)\n",
    "        self.d_k = Tensor(d_k, mindspore.float32)\n",
    "        \n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        scores = ops.matmul(Q, K.swapaxes(-1, -2)) / ops.sqrt(self.d_k)# scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores = scores.masked_fill(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = ops.softmax(scores)\n",
    "        context = ops.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interim-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, d_v, n_heads):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.W_Q = Dense(d_model, d_k * n_heads)\n",
    "        self.W_K = Dense(d_model, d_k * n_heads)\n",
    "        self.W_V = Dense(d_model, d_v * n_heads)\n",
    "        self.linear = Dense(n_heads * d_v, d_model)\n",
    "        self.layer_norm = nn.LayerNorm((d_model, ), epsilon=1e-5)\n",
    "        self.attention = ScaledDotProductAttention(d_k)\n",
    "        \n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.shape[0]\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).swapaxes(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).swapaxes(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).swapaxes(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).tile((1, n_heads, 1, 1)) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = self.attention(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.swapaxes(1, 2).view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = self.linear(context)\n",
    "        return self.layer_norm(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "official-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForward(nn.Cell):\n",
    "    def __init__(self, d_ff, d_model):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.layer_norm = nn.LayerNorm((d_model, ), epsilon=1e-5)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def construct(self, inputs):\n",
    "        residual = inputs # inputs : [batch_size, len_q, d_model]\n",
    "        output = self.relu(self.conv1(inputs.swapaxes(1, 2)))\n",
    "        output = self.conv2(output).swapaxes(1, 2)\n",
    "        return self.layer_norm(output + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incredible-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, d_v, n_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, d_k, d_v, n_heads)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model)\n",
    "        \n",
    "    def construct(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "greater-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, d_v, n_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, d_k, d_v, n_heads)\n",
    "        self.dec_enc_attn = MultiHeadAttention(d_model, d_k, d_v, n_heads)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model)\n",
    "        \n",
    "    def construct(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "atmospheric-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, src_vocab_size, d_model, d_k, d_v, n_heads, d_ff, n_layers, src_len):\n",
    "        super().__init__()\n",
    "        self.src_emb = Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = Embedding.from_pretrained_embedding(get_sinusoid_encoding_table(src_len+1, d_model), freeze=True)\n",
    "        self.layers = nn.CellList([EncoderLayer(d_model, d_k, d_v, n_heads, d_ff) for _ in range(n_layers)])\n",
    "        # temp positional indexes\n",
    "        self.pos = Tensor([[1, 2, 3, 4, 0]])\n",
    "        \n",
    "    def construct(self, enc_inputs):\n",
    "        # enc_inputs : [batch_size x source_len]\n",
    "        enc_outputs = self.src_emb(enc_inputs) + self.pos_emb(self.pos)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seeing-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, tgt_vocab_size, d_model, d_k, d_v, n_heads, d_ff, n_layers, tgt_len):\n",
    "        super().__init__()\n",
    "        self.tgt_emb = Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = Embedding.from_pretrained_embedding(get_sinusoid_encoding_table(tgt_len+1, d_model), freeze=True)\n",
    "        self.layers = nn.CellList([DecoderLayer(d_model, d_k, d_v, n_heads, d_ff) for _ in range(n_layers)])\n",
    "\n",
    "    def construct(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        # dec_inputs : [batch_size x target_len]\n",
    "        dec_outputs = self.tgt_emb(dec_inputs) + self.pos_emb(Tensor([[5,1,2,3,4]]))\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)\n",
    "        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs)\n",
    "        dec_self_attn_mask = ops.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n",
    "        \n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)\n",
    "\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "presidential-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, d_v, n_heads, d_ff, n_layers, src_vocab_size, tgt_vocab_size, src_len, tgt_len):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, d_k, d_v, n_heads, d_ff, n_layers, src_len)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, d_k, d_v, n_heads, d_ff, n_layers, tgt_len)\n",
    "        self.projection = Dense(d_model, tgt_vocab_size, has_bias=False)\n",
    "\n",
    "    def construct(self, enc_inputs, dec_inputs):\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        dec_logits = self.projection(dec_outputs) # dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]\n",
    "        return dec_logits.view((-1, dec_logits.shape[-1])), enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hairy-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "# Transformer Parameters\n",
    "# Padding Should be Zero\n",
    "src_vocab = {'P': 0, 'ich': 1, 'mochte': 2, 'ein': 3, 'bier': 4}\n",
    "src_vocab_size = len(src_vocab)\n",
    "\n",
    "tgt_vocab = {'P': 0, 'i': 1, 'want': 2, 'a': 3, 'beer': 4, 'S': 5, 'E': 6}\n",
    "number_dict = {i: w for i, w in enumerate(tgt_vocab)}\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "\n",
    "src_len = 6 # length of source\n",
    "tgt_len = 5 # length of target\n",
    "\n",
    "d_model = 512  # Embedding Size\n",
    "d_ff = 2048  # FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_layers = 6  # number of Encoder of Decoder Layer\n",
    "n_heads = 8  # number of heads in Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pacific-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(d_model, d_k, d_v, n_heads, d_ff, n_layers, src_vocab_size, tgt_vocab_size, src_len, tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "activated-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=0.0001)\n",
    "# print(model.trainable_params())\n",
    "enc_inputs, dec_inputs, target_batch = make_batch(sentences, src_vocab, tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f7e451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(enc_inputs, dec_inputs, target_batch):\n",
    "    outputs, _, _, _, = model(enc_inputs, dec_inputs)\n",
    "    loss = criterion(outputs, target_batch)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "223f4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = ops.value_and_grad(forward, None, optimizer.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c96e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "@mindspore.jit\n",
    "def train_step(enc_inputs, dec_inputs, target_batch):\n",
    "    loss, grads = grad_fn(enc_inputs, dec_inputs, target_batch)\n",
    "    optimizer(grads)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "human-reverse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:30.934.784 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/3030654789.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:31.085.333 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/1296245474.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:31.085.953 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/1296245474.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:31.086.786 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/1296245474.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:35.478.043 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/2926503423.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:35.478.088 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/2926503423.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:35.663.493 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/3030654789.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:35.663.514 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/1296245474.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:35.665.780 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/1296245474.py]\n",
      "[ERROR] CORE(1265263,7f03d442f4c0,python):2024-04-16-15:48:35.667.354 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_1265263/1296245474.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 2.367968\n",
      "Epoch: 0002 cost = 0.938194\n",
      "Epoch: 0003 cost = 0.512835\n",
      "Epoch: 0004 cost = 0.167661\n",
      "Epoch: 0005 cost = 0.048837\n",
      "Epoch: 0006 cost = 0.010902\n",
      "Epoch: 0007 cost = 0.003625\n",
      "Epoch: 0008 cost = 0.001862\n",
      "Epoch: 0009 cost = 0.001336\n",
      "Epoch: 0010 cost = 0.001196\n",
      "Epoch: 0011 cost = 0.001198\n",
      "Epoch: 0012 cost = 0.001234\n",
      "Epoch: 0013 cost = 0.001247\n",
      "Epoch: 0014 cost = 0.001202\n",
      "Epoch: 0015 cost = 0.001100\n",
      "Epoch: 0016 cost = 0.000960\n",
      "Epoch: 0017 cost = 0.000809\n",
      "Epoch: 0018 cost = 0.000667\n",
      "Epoch: 0019 cost = 0.000544\n",
      "Epoch: 0020 cost = 0.000444\n"
     ]
    }
   ],
   "source": [
    "model.set_train()\n",
    "\n",
    "# Training\n",
    "for epoch in range(20):\n",
    "    # hidden : [num_layers * num_directions, batch, hidden_size]\n",
    "    loss = train_step(enc_inputs, dec_inputs, target_batch.view(-1))\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss.asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rubber-difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "predict, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
    "predict = predict.asnumpy().argmax(1)\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "postal-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showgraph(attn):\n",
    "    attn = attn[-1].squeeze(0)[0]\n",
    "    attn = attn.asnumpy()\n",
    "    fig = plt.figure(figsize=(n_heads, n_heads)) # [n_heads, n_heads]\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attn, cmap='viridis')\n",
    "    ax.set_xticklabels(['']+sentences[0].split(), fontdict={'fontsize': 14}, rotation=90)\n",
    "    ax.set_yticklabels(['']+sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first head of last state enc_self_attns')\n",
    "showgraph(enc_self_attns)\n",
    "\n",
    "print('first head of last state dec_self_attns')\n",
    "showgraph(dec_self_attns)\n",
    "\n",
    "print('first head of last state dec_enc_attns')\n",
    "showgraph(dec_enc_attns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "4cc655d51980dc1bed66c9250264d1811f0d2f81f66ea1a977ce405bd6de04fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
